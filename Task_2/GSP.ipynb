{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7syxtwOSTPZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liang\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\liang\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b6oGK3x_x7z"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3CQpwlB7_x7z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_triplegs(df, timestamp_col='started_at'):\n",
    "    \"\"\"\n",
    "    Preprocess the triplegs data by extracting sequences of triplegs for each user.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The triplegs DataFrame.\n",
    "    timestamp_col (str): The name of the column containing the timestamp.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of sequences of triplegs for each user as lists of tuples.\n",
    "    \"\"\"\n",
    "    # Convert the timestamp column to datetime\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "\n",
    "    # Define the starting date and filter data to include only the first 30 days\n",
    "    start_date = pd.to_datetime('1900-01-01').tz_localize('UTC')\n",
    "    end_date = start_date + pd.Timedelta(days=30)\n",
    "\n",
    "    # Use .copy() to avoid SettingWithCopyWarning\n",
    "    df = df.loc[(df[timestamp_col] >= start_date) & (df[timestamp_col] < end_date)].copy()\n",
    "\n",
    "    # Function to convert LINESTRING to integer coordinates\n",
    "    def linestring_to_int_coords(linestring):\n",
    "        # Extract the coordinates from the LINESTRING\n",
    "        coords = re.findall(r'(\\d+\\.\\d+ \\d+\\.\\d+)', linestring)\n",
    "        # Convert the coordinates to tuples of integers\n",
    "        int_coords = [tuple(map(int, map(float, coord.split()))) for coord in coords]\n",
    "        return int_coords  # Return as a list of tuples\n",
    "\n",
    "    # Convert the LINESTRING sequences to integer coordinates\n",
    "    df['geom'] = df['geom'].apply(linestring_to_int_coords)\n",
    "\n",
    "    # Extract sequences of triplegs for each user\n",
    "    user_sequences = df.groupby('user_id')['geom'].apply(list).tolist()\n",
    "\n",
    "    # Flatten the list of lists into a single list of tuples\n",
    "    final_output = []\n",
    "    for sequence in user_sequences:\n",
    "        final_output.extend(sequence)  \n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FgEVbX-sK5Tx"
   },
   "outputs": [],
   "source": [
    "def split_long_triplegs(df, max_length=1000):\n",
    "    \"\"\"\n",
    "    Split long triplegs into shorter sub-triplegs.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The triplegs DataFrame.\n",
    "    max_length (int): The maximum length of a tripleg.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with long triplegs split into shorter sub-triplegs.\n",
    "    \"\"\"\n",
    "    def split_geom(geom, max_length):\n",
    "        points = geom.split(',')\n",
    "        sub_triplegs = [','.join(points[i:i + max_length]) for i in range(0, len(points), max_length)]\n",
    "        return sub_triplegs\n",
    "\n",
    "    new_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        geoms = split_geom(row['geom'], max_length)\n",
    "        for geom in geoms:\n",
    "            new_row = row.copy()\n",
    "            new_row['geom'] = geom\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCZOHzaO_x7z"
   },
   "source": [
    "## Apply GSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ShWEKZGxDu1X"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "#contiguous matching\n",
    "def generate_candidates(sequences, length):\n",
    "    \"\"\"Generate candidate sequences of a given length.\"\"\"\n",
    "    candidates = set()\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq) - length + 1):\n",
    "            candidates.add(tuple(seq[i:i + length]))\n",
    "    return candidates\n",
    "\n",
    "def is_subsequence(candidate, sequence):\n",
    "    \"\"\"Check if candidate is a subsequence of sequence.\"\"\"\n",
    "    it = iter(sequence)\n",
    "    return all(item in it for item in candidate)\n",
    "\n",
    "#discontinuous matching\n",
    "# def generate_candidates(sequences, length):\n",
    "#     \"\"\"Generate candidate sequences of a given length, allowing non-contiguous elements.\"\"\"\n",
    "#     candidates = set()\n",
    "#     for seq in sequences:\n",
    "#         for indices in combinations(range(len(seq)), length):\n",
    "#             # Create a candidate using the indices to select elements from the sequence\n",
    "#             candidates.add(tuple(tuple(seq[i]) for i in indices))\n",
    "#     return candidates\n",
    "\n",
    "# def is_subsequence(candidate, sequence):\n",
    "#     \"\"\"Check if the candidate sequence is a subsequence of the sequence, ignoring elements in between.\"\"\"\n",
    "#     it = iter(sequence)  # Create an iterator for the sequence\n",
    "#     return all(item in it for item in candidate)\n",
    "\n",
    "def count_support(candidates, sequences):\n",
    "    \"\"\"Count the support of each candidate sequence in the dataset.\"\"\"\n",
    "    support_count = defaultdict(int)\n",
    "    for candidate in candidates:\n",
    "        for seq in sequences:\n",
    "            if is_subsequence(candidate, seq):\n",
    "                support_count[candidate] += 1\n",
    "    return support_count\n",
    "\n",
    "\n",
    "def prune_candidates(support_count, min_support):\n",
    "    \"\"\"Prune candidate sequences that do not meet the minimum support threshold.\"\"\"\n",
    "    return {seq: count for seq, count in support_count.items() if count >= min_support}\n",
    "\n",
    "def generate_new_candidates(frequent_sequences, length):\n",
    "    \"\"\"Generate new candidate sequences by joining frequent sequences.\"\"\"\n",
    "    new_candidates = set()\n",
    "    frequent_sequences = list(frequent_sequences)\n",
    "    for seq1, seq2 in combinations(frequent_sequences, 2):\n",
    "        # Join sequences if they can form a new length candidate\n",
    "        if seq1[1:] == seq2[:-1]:\n",
    "            new_candidates.add(seq1 + (seq2[-1],))\n",
    "    return new_candidates\n",
    "\n",
    "def gsp(sequences, min_support):\n",
    "    \"\"\"Implement the GSP algorithm to mine sequential patterns.\"\"\"\n",
    "    length = 2\n",
    "    frequent_sequences = generate_candidates(sequences, length)\n",
    "    all_frequent_sequences = []\n",
    "\n",
    "    while frequent_sequences:\n",
    "        support_count = count_support(frequent_sequences, sequences)\n",
    "        frequent_sequences = prune_candidates(support_count, min_support)\n",
    "\n",
    "        all_frequent_sequences.extend(frequent_sequences.keys())\n",
    "\n",
    "        length += 1\n",
    "        frequent_sequences = generate_new_candidates(frequent_sequences.keys(), length)\n",
    "\n",
    "    return all_frequent_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TClCAJf9_x70"
   },
   "source": [
    "## Save Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS7LTzhC_x70"
   },
   "outputs": [],
   "source": [
    "def save_gsp_results(gsp_results, output_file):\n",
    "    \"\"\"\n",
    "    Save the GSP results to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    gsp_results (list): A list of frequent sequences.\n",
    "    output_file (str): The path to the output CSV file.\n",
    "    \"\"\"\n",
    "    sequences_df = pd.DataFrame(gsp_results, columns=['Sequence'])\n",
    "    sequences_df.to_csv(output_file, index=False)\n",
    "    print(f\"GSP results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUSSx5yT_x70"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./triplegsA.csv' , compression='zip')\n",
    "\n",
    "# Split long triplegs into shorter sub-triplegs\n",
    "df = split_long_triplegs(df)\n",
    "\n",
    "# Preprocess the data and limit to the first month\n",
    "sequences = preprocess_triplegs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42gCSb7NPUbV",
    "outputId": "2c989a38-27f1-40a3-8a4d-29f7d2cd1912"
   },
   "outputs": [],
   "source": [
    "# Define the minimum support threshold dynamically as x% of the dataset\n",
    "min_support = int(0.00001 * len(sequences)) \n",
    "print(f\"Minimum support threshold: {min_support}\")\n",
    "\n",
    "# Apply the GSP algorithm to find frequent sequences\n",
    "frequent_sequences = gsp(sequences, min_support)\n",
    "\n",
    "save_gsp_results(frequent_sequences, 'frequent_sequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Cell to calculate the average sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('frequent_sequences_A.csv')\n",
    "\n",
    "# Function to calculate the length of a pattern\n",
    "def calculate_pattern_length(pattern):\n",
    "    # Parse the pattern string into a list of tuples\n",
    "    pattern_list = ast.literal_eval(pattern)\n",
    "    # Return the length of the pattern\n",
    "    return len(pattern_list)\n",
    "\n",
    "# Apply the function to calculate the length of each pattern\n",
    "df['Pattern_Length'] = df['Pattern'].apply(calculate_pattern_length)\n",
    "\n",
    "# Calculate the average length of the patterns\n",
    "average_length = df['Pattern_Length'].mean()\n",
    "\n",
    "print(f'The average length of the patterns is: {average_length}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
